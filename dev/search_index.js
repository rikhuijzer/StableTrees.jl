var documenterSearchIndex = {"docs":
[{"location":"#StableTrees","page":"StableTrees","title":"StableTrees","text":"","category":"section"},{"location":"","page":"StableTrees","title":"StableTrees","text":"This package implements the Stable and Interpretable RUle Sets (SIRUS) for classification and regression problems (Bénard et al., 2021).","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"The trees are stabilized by first defining an empirical CART-splitting criterion. In the context of binary classification, \"maximizing the so-called empirical CART-splitting criterion is equivalent to maximizing the criterion on Gini impurity\". Gini impurity is defined as (James et al., 2014; Eq. 8.6):","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"G = sum_k=1^K overlinep_mk (1 - overlinep_mk)","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"where","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"overlinep_mk represents the proportion of training observations in the m-th region that are from the k-th class.","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"Specifically, in Equation 4.1 the empirical CART-splitting criterion is defined as","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"newcommandidentity1kern-025emtextl\n\nbeginaligned\nL_n(H hatq_nr^(j)) = frac1N_n(H) sum_i=1^n (Y_i - overlineY_H)^2\n    identity_boldX_i in H \n\n- frac1N_n(H) sum_i=1^n (Y_i - overlineY_H_L identity_X_i^(j)  hatq_nr^(j)\n    - overlineY_H_R identity_X_i^(j) ge hatq_nr^(j))^2 identity_boldX_i in H\n\nendaligned","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"where","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"H is some node,\noverlineY_H is the average of the Y_i's such that boldX_i in H,\nN_n(H) is the number of data points boldX_i falling into H, and\nthe empirical r-th q-quantile hatq_nr^(j) of  X_i^(j)  X_n^(j)  for r in 1  q - 1 is defined in Equation 4.2 by","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"newcommandidentity1kern-025emtextl\n\nhatq_nr^(j) = inf  x in Reals    frac1n sum_i=1^n identity_x_i^(j) le x ge fracrq ","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"Note that this definition is for a tree built with the entire dataset without resampling. When 2 le q (q is typically 10), then the theoretical q-quantiles are defined by","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"q_r^*(j) = inf  x in Reals    mathbbP (X^(j) le x) ge fracrq ","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"The empircal r-th q-quantile hatq_nr^(j) can be used to determine the splits, namely the left and right subtrees obtained after splitting are defined as","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"H_L =  x in H    boldx^(j)  hatq_nr^(j)     H_R =  x in H    boldx^(j) ge hatq_nr^(j) ","category":"page"},{"location":"","page":"StableTrees","title":"StableTrees","text":"Or in other words, the node splits are restricted to to the q-empirical quantiles of the marginals X^(1)X^(p), with typically q = 10 (Bénard et al., 2021). Setting q = 10 causes more stable trees because it splits the input space in a grid of 10^p hyperrectangles for p features and this number has empirically been found to be accurate.","category":"page"}]
}
